---
title: "HS614 HW#3"
author: "Tiffany Chua"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Working Directory}
getwd()
```

# HS614: Homework #3
For this HW use the diabetes dataset.

Exploratory Data Analysis:
1. Explore the data
2. How many rows and columns?
3. Any NAs? If yes, which columns?
4. Any strange values? If yes, what to do?
5. Any correlation between features?
6. Statistics of the columns and some exploratory plots (bar plot, histogram, boxplot ...)

Build at least 4 different predictive models that can predict (classify) Diabetic patients. Compare the performance of the models.

Column definitions of this dataset are given in table 1 of this paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8306487/

***

```{r Libraries}
library(Amelia)
library(ggplot2)
library(GGally)
library(caTools)
library(caret)
library(class)
library(e1071)
library(psych)
library(corrplot)
library(ISLR)
library(cluster)
library(datasets)
library(pastecs)
library(psych)
library(corrplot)
library(stats)
library(Hmisc)
library(mice)
library(VIM)
library(dplyr)
library(hrbrthemes)
library(tidyverse)
library(factoextra)
library(pROC)
library(rpart)
library(rpart.plot)
library(randomForest)
library(animation)
```

```{r Read in Dataset}
diab <- read.csv("./diabetes.csv")
head(diab)
str(diab)
```

## Variable Definitions
1. Pregnancy - Frequency of pregnancy
2. Glucose - Concentration of plasma glucose (mg/dL)
3. BP - Diastolic blood pressure (mmHg)
4. Skin - Tricep skinfold thickness (mm)
5. Insulin - Two-hour serum insulin (mu U/ml)
6. BMI - Body mass index (kg/m2)
7. Pedigree - A pedigree function for diabetes
8. Age - Age (log(years))

```{r Outcome Factor}
diab$Outcome = factor(diab$Outcome)
str(diab)

table(diab$Outcome)
```

## Rows & Columns
```{r}
nrow(diab)
ncol(diab)
```

## Missing & Strange Variables
```{r Missing/NA}
sum(is.na(diab))
missmap(diab)

#Note: While there are no NA variables, missing data points seem to have been replaced with a value of 0 in columns
```
Note: While there are no NA variables, missing data points seem to have been replaced with a value of 0 in columns.

```{r Rows with Value 0 per Column}
sum(diab$Glucose == 0)
sum(diab$BloodPressure == 0)
sum(diab$SkinThickness == 0)
sum(diab$Insulin == 0)
sum(diab$BMI == 0)
sum(diab$DiabetesPedigreeFunction == 0)
sum(diab$Age == 0)

#Strange Values:
#The following columns returned values of 0 Glucose, BloodPressure, SkinThickness, Insulin, and BMI; It is likely that missing/NA variables for these columns were replaced with 0, as 0 is a highly unlikely and unrealistic observation for these features
```

**Strange Values**
The following columns returned values of 0: Glucose, BloodPressure, SkinThickness, Insulin, and BMI. It is likely that missing/NA variables for these columns were replaced with 0, as 0 is a highly unlikely and unrealistic observation for these features.

```{r Change Strange Values to NA}
#What to do with the strange values?
diab1 <- diab

#Turn strange (0) values into NA
diab1$Glucose[diab1$Glucose == 0] = NA
diab1$BloodPressure[diab1$BloodPressure == 0] = NA
diab1$SkinThickness[diab1$SkinThickness == 0] = NA
diab1$Insulin[diab1$Insulin == 0] = NA
diab1$BMI[diab1$BMI == 0] = NA

sum(is.na(diab1))
missmap(diab1)

#I will use mean imputation on the NA variables in the Predictive Models section (after Train/Test Split)
```
What to do with the strange variables?
1. Turn strange (0) values into NA.
2. I will use mean imputation on the NA variables in the Predicive Models section (after Train/Test Split).

*** 

# Exploratory Data Analysis

## Initial Read
### Descriptive Statistics
```{r Descriptive Statistics}
stat.desc(diab1)
summary(diab1)
```

### Correlations
```{r Correlations}
diab_num <- diab1[1:8]

M <- cor(diab_num,
         method = "pearson")
M
corrplot(M,
         method = "square")
cor.plot(diab_num)

#Highest Correlating Variables:
# BMI & SkinThickness = 0.65
# Insulin & Glucose = 0.58
# Pregnancies & Age = 0.54
# BloodPressure & Age = 0.33
# BMI & BloodPressure = 0.29
```
Highest Correlating Variables:
* BMI & SkinThickness = 0.65
* Insulin & Glucose = 0.58
* Pregnancies & Age = 0.54
* BloodPressure & Age = 0.33
* BMI & BloodPressure = 0.29

## Plots
```{r ggPairs}
ggpairs(diab1)
```

### Outcome Barplot
```{r Bar}
ggplot(diab1,
       aes(Outcome)) +
  geom_bar()
```

### Histograms, grouped by Outcome
```{r Histogram}
# Grouped
# p <- data %>%
#   ggplot( aes(x=value, fill=type)) +
#     geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
#     scale_fill_manual(values=c("#69b3a2", "#404080")) +
#     theme_ipsum() +
#     labs(fill="")

Glucose_hist <- diab1 %>%
  ggplot(aes(x = Glucose,
             fill = Outcome)) +
  geom_histogram(binwidth = 5)
Glucose_hist

BP_hist <- diab1 %>%
  ggplot(aes(x = BloodPressure,
             fill = Outcome)) +
  geom_histogram(binwidth = 5)
BP_hist

BMI_hist <- diab1 %>%
  ggplot(aes(x = BMI,
             fill = Outcome)) +
  geom_histogram(binwidth = 2)
BMI_hist

Ped_hist <- diab1 %>%
  ggplot(aes(x = DiabetesPedigreeFunction,
             fill = Outcome)) +
  geom_histogram(binwidth = 0.075)
Ped_hist

Age_hist <- diab1 %>%
  ggplot(aes(x = Age,
             fill = Outcome)) +
  geom_histogram(binwidth = 2)
Age_hist
```

### Scatter Plots, grouped by Outcome
```{r Scatter Plots}
#Highest Correlating Variables:
# BMI & SkinThickness = 0.65
# Insulin & Glucose = 0.58
# Pregnancies & Age = 0.54
# BloodPressure & Age = 0.33
# BMI & BloodPressure = 0.29

# BMI & SkinThickness = 0.65
BMI_Skin <- ggplot(data = diab1,
                   aes(x = BMI,
                       y = SkinThickness,
                       color = Outcome),
                   na.rm = TRUE) +
  geom_point(size = 0.5) +
  geom_smooth(method = lm) +
  labs(title = "BMI vs. Skin Thickness")
BMI_Skin

# Insulin & Glucose = 0.58
Insu_Glucose <- ggplot(data = diab1,
                       aes(x = Insulin,
                           y = Glucose,
                           color = Outcome),
                       na.rm = TRUE) +
  geom_point(size = 0.5) +
  geom_smooth(method = lm) +
  labs(title = "Insulin vs. Glucose")
Insu_Glucose

# Pregnancies & Age = 0.54
Age_Preg <- ggplot(data = diab1,
                   aes(x = Age,
                       y = Pregnancies,
                       color = Outcome),
                   na.rm = TRUE) +
  geom_point(size = 0.5) +
  geom_smooth(method = lm) +
  labs(title = "Age vs. Pregnancies")
Age_Preg

# BloodPressure & Age = 0.33
Age_BP <- ggplot(data = diab1,
                    aes(x = Age,
                        y = BloodPressure,
                        color = Outcome),
                    na.rm = TRUE) +
  geom_point(size = 0.5) +
  geom_smooth(method = lm) +
  labs(title = "Age vs. Blood Pressure")
Age_BP

# Glucose & Age = 0.32
Age_Glucose <- ggplot(data = diab1,
                      aes(x = Age,
                          y = Glucose,
                          color = Outcome),
                      na.rm = TRUE) +
  geom_point(size = 0.5) +
  geom_smooth(method = lm) +
  labs(title = "Age vs. Glucose")
Age_Glucose

# BloodPressure & BMI = 0.29
BMI_BP <- ggplot(data = diab1,
                 aes(x = BMI,
                     y = BloodPressure,
                     color = Outcome),
                 na.rm = TRUE) +
  geom_point(size = 0.5) +
  geom_smooth(method = lm) +
  labs(title = "BMI vs. Blood Pressure")
BMI_BP
```

***

# Predictive Models
## Train & Test Split
```{r Sample Split}
set.seed(123)
split <- sample.split(diab1$Outcome,
                      SplitRatio = 0.8)
diab.train <- subset(diab1,
                     split == TRUE)
diab.test <- subset(subset(diab1,
                           split == FALSE))

nrow(diab.test)
nrow(diab.train)
```

```{r Train Head/Str}
head(diab.train)
str(diab.train)
```

```{r Rows & Columns}
nrow(diab.train)
ncol(diab.train)
```

```{r Train/Test NA Check}
sum(is.na(diab.train))
sum(is.na(diab.test))
```

```{r Train Mean Imputation}
diab.train$Glucose[is.na(diab.train$Glucose)] <- mean(diab.train$Glucose,
                                          na.rm = TRUE)
diab.train$BloodPressure[is.na(diab.train$BloodPressure)] <- mean(diab.train$BloodPressure,
                                                      na.rm = TRUE)
diab.train$SkinThickness[is.na(diab.train$SkinThickness)] <- mean(diab.train$SkinThickness,
                                                      na.rm = TRUE)
diab.train$Insulin[is.na(diab.train$Insulin)] <- mean(diab.train$Insulin,
                                          na.rm = TRUE)
diab.train$BMI[is.na(diab.train$BMI)] <- mean(diab.train$BMI,
                                  na.rm = TRUE)

sum(is.na(diab.train))

str(diab.train)
```

```{r Test Mean Imputation}
diab.test$Glucose[is.na(diab.test$Glucose)] <- mean(diab.train$Glucose,
                                          na.rm = TRUE)
diab.test$BloodPressure[is.na(diab.test$BloodPressure)] <- mean(diab.train$BloodPressure,
                                                      na.rm = TRUE)
diab.test$SkinThickness[is.na(diab.test$SkinThickness)] <- mean(diab.train$SkinThickness,
                                                      na.rm = TRUE)
diab.test$Insulin[is.na(diab.test$Insulin)] <- mean(diab.train$Insulin,
                                          na.rm = TRUE)
diab.test$BMI[is.na(diab.test$BMI)] <- mean(diab.train$BMI,
                                  na.rm = TRUE)

sum(is.na(diab.test))

head(diab.test)
```

## Logistic Regression

### Logistic Regression Models
```{r Log Model 1}
logModel1 <- glm(formula = Outcome ~ . , 
                 family = binomial,
                 data = diab.train)
summary(logModel1)

#Based on logModel1, the significant values are as follows:
# ***: Glucose
# *: BMI 
# .: Insulin

#AIC: 284.17
```
Based on logModel1, the significant values are as follows:
* ***: Glucose
* *: BMI 
* .: Insulin

AIC: 284.17

```{r Log Model 2}
logModel2 <- glm(formula = Outcome ~ Glucose + BMI + Insulin, 
                 family = binomial,
                 data = diab.train)
summary(logModel2)

#Based on logModel2, the significant values are as follows:
# ***: Glucose, BMI
# .: Insulin

#AIC: 289.49
#Because this AIC is higher  than for logModel1 (289.49 > 284.17), we can assume that logModel1 is better than logModel2
```
Based on logModel2, the significant values are as follows:
* ***: Glucose, BMI
* .: Insulin

AIC: 289.49
Because this AIC is higher  than for logModel1 (289.49 > 284.17), we can assume that logModel1 is better than logModel2.

```{r Log Model 3}
logModel3 <- glm(formula = Outcome ~ Glucose + BMI, 
                 family = binomial,
                 data = diab.train)
summary(logModel3)

#Based on logModel3, the significant values are as follows:
# ***: Glucose, BMI

#AIC: 590.81
#Because this AIC is higher  than for logModel1 and logModel2 (590.81 > 289.49 > 284.17), we can assume that this model is not as good as logModel1 or logModel2
```
Based on logModel3, the significant values are as follows:
* ***: Glucose, BMI

AIC: 590.81
Because this AIC is higher  than for logModel1 and logModel2 (590.81 > 289.49 > 284.17), we can assume that this model is not as good as logModel1 or logModel2.

### Logistic Regression Prediction
```{r Log Predict}
Outcome.predictions <- predict(logModel1,
                               diab.test,
                               type = "response")

log.results <- cbind(Outcome.predictions,
                     diab.test$Outcome)

results.class <- ifelse(log.results > 0.5, 1,0) 
colnames(results.class) <- c("pred", "real")
results.class <- as.data.frame(results.class)

head(results.class)
```

### Logistic Regression Confusion Matrix
```{r Log Confusion Matrix}
table(diab.test$Outcome,
      results.class$pred)
```

## K-Nearest Neighbor
```{r}
head(diab.train)
head(diab.test)

str(diab.train)
str(diab.test)

sum(is.na(diab.train))
sum(is.na(diab.test))
```

### KNN Fitting
```{r KNN Fitting 1}
#Fitting K-NN to the Training set and Predicting the Test set results
vec = c()
k_vec = c()

y_pred = knn(train = diab.train[ , -9],
             test = diab.test[ , -9],
             cl = diab.train[ , 9],
             k = 10)

head(y_pred)
```

```{r KNN Fitting 2}
#Fitting K-NN to the Training set and Predicting the Test set results
vec = c()
k_vec = c()

for (k in 1:50){
y_pred = knn(train = diab.train[ , -9],
             test = diab.test[ , -9],
             cl = diab.train[ , 9],
             k = k)

error = mean(y_pred != diab.test$Outcome) #measure of accuracy
k_vec = c(k_vec, k)
vec = c(vec, error)
}

head(vec)
```

```{r KNN Error}
df.error = data.frame(k_vec, vec)
head(df.error)
```

### Elbow Method
```{r Elbow Method}
ggplot(df.error,
       aes(k_vec, vec)) +
  geom_line()
```

### KNN Confusion Matrix
```{r KNN Confusion Matrix}
y_pred = knn(train = diab.train[, -9],
             test = diab.test[, -9],
             cl = diab.train[, 9],
             k = 9)

# Making the Confusion Matrix
cm = table(diab.test[, 9], y_pred)
cm

confusionMatrix(diab.test[ , 9],
                y_pred)
```
Kappa: 0.4268

## Decision Tree & Random Forest

```{r}
head(diab.train)
head(diab.test)

str(diab.train)
str(diab.test)

sum(is.na(diab.train))
sum(is.na(diab.test))
```

### Decision Tree
#### Tree
```{r Tree}
tree = rpart(formula = Outcome ~ .,
             method = "class",
             data = diab.train)
```

#### Tree Prediction
```{r Tree Pred}
#Predicting the Test Set Results
y_pred = predict(tree,
                 newdata = diab.test)

head(y_pred)
```

```{r Tree Pred Class}
y_pred_class = ifelse(y_pred[, "0"] >= 0.5,
                      0, 1)
```

#### Tree Confusion Matrix
```{r Tree Confusion Matrix}
# Making the Confusion Matrix
cm = table(diab.test$Outcome,
           y_pred_class)

cm
```

#### Tree ROC
```{r Tree ROC}
result.roc = roc(diab.test$Outcome,
                 y_pred[ ,"0"])

result.roc
plot(result.roc)
```

#### Decision Trees
```{r Decision Trees}
plot(tree,
     uniform=TRUE,
     main="Diabetes Outcome")
text(tree,
     use.n=TRUE,
     all=TRUE)

prp(tree)
```

### Random Forest
```{r Random Forest}
RF <- randomForest(formula = Outcome ~ .,
                   method='class',
                   data = diab.train)
RF
```

```{r Importance}
importance(RF)
#MeanDecreaseGini --> Importance (IncNodePurity)
```

```{r}
diab.test1 <- diab.test[-9]
head(diab.test1)
```

#### Random Forest Probabilities
```{r RF Prob}
y_prob = predict(RF,
                 newdata = diab.test1,
                 type="prob")

head(y_prob)
```

#### Random Forest Prediction
```{r RF Pred}
# Predicting the Test set results
y_pred = predict(RF,
                 newdata = diab.test)
```

```{r RF Confusion Matrix}
confusionMatrix(diab.test[ , 9],
                y_pred)
```

